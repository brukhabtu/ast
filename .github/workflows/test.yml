name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"
  UV_VERSION: "0.4.18"

jobs:
  # Fast feedback - Unit tests only
  unit-tests:
    name: Unit Tests (Fast Feedback)
    runs-on: ubuntu-latest
    strategy:
      fail-fast: true
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11", "3.12"]
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ runner.os }}-uv-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-uv-${{ matrix.python-version }}-
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run unit tests
        run: |
          uv run pytest tests/unit -m unit -v --maxfail=5 --tb=short
        timeout-minutes: 5

  # Integration tests - Internal component testing
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    strategy:
      matrix:
        python-version: ["3.9", "3.11"]
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run integration tests
        run: |
          uv run pytest tests/integration -m integration -v
        timeout-minutes: 10

  # Full test suite with coverage
  full-test-suite:
    name: Full Test Suite + Coverage
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run full test suite with coverage
        run: |
          uv run pytest tests/ -m "not e2e" --cov --cov-report=xml --cov-report=html
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
      
      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: htmlcov/
      
      - name: Check coverage threshold
        run: |
          uv run python -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('coverage.xml')
          root = tree.getroot()
          coverage = float(root.attrib['line-rate']) * 100
          print(f'Coverage: {coverage:.2f}%')
          if coverage < 80:
              raise SystemExit(f'Coverage {coverage:.2f}% is below 80% threshold')
          "

  # E2E tests - Only on main branch
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, full-test-suite]
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run E2E tests
        run: |
          uv run pytest tests/e2e -m e2e -v
        timeout-minutes: 30

  # Performance benchmarks
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run performance benchmarks
        run: |
          uv run pytest tests/ -m performance --benchmark-only --benchmark-json=benchmark.json
      
      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true

  # Code quality checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Run Black formatter check
        run: |
          uv run black --check .
      
      - name: Run Ruff linter
        run: |
          uv run ruff check .
      
      - name: Run MyPy type checker
        run: |
          uv run mypy ast_lib tests
        continue-on-error: true  # Type checking is informational initially

  # Test the test infrastructure itself
  test-infrastructure:
    name: Test Infrastructure Meta-Tests
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
      
      - name: Install dependencies
        run: |
          uv venv
          uv pip install -e ".[dev]"
      
      - name: Test that fixtures work correctly
        run: |
          uv run pytest tests/test_infrastructure.py -v
      
      - name: Validate test markers
        run: |
          uv run pytest --markers
      
      - name: Check test collection
        run: |
          uv run pytest --collect-only -q | head -20